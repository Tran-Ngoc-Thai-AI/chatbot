import streamlit as st
import os
from datetime import datetime
from langchain_core.messages import HumanMessage, AIMessage
from user_constants import LOG_FILE
from user_utils import save_log
from user_core_logic import get_vectorstore, get_rag_chain

st.set_page_config(page_title="Chat AI N·ªôi b·ªô", page_icon="ü§ñ", layout="wide")

# --- SIDEBAR ---
with st.sidebar:
    st.title("Qu·∫£n l√Ω")
    if os.path.exists(LOG_FILE):
        with open(LOG_FILE, "rb") as f:
            st.download_button(
                label="üì• T·∫£i file Log",
                data=f,
                file_name=f"logs_{datetime.now().strftime('%d%m_%H%M')}.jsonl",
                mime="application/jsonl"
            )

# --- CHAT UI ---
st.title("ü§ñ Chat v·ªõi T√†i li·ªáu Doanh Nghi·ªáp")

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message("user" if isinstance(message, HumanMessage) else "assistant"):
        st.markdown(message.content)

if user_input := st.chat_input("Nh·∫≠p c√¢u h·ªèi t·∫°i ƒë√¢y..."):
    st.session_state.messages.append(HumanMessage(content=user_input))
    with st.chat_message("user"):
        st.markdown(user_input)

# 2. Ph·∫£n h·ªìi c·ªßa Assistant
    with st.chat_message("assistant"):
        # T·∫°o placeholder ƒë·ªÉ hi·ªÉn th·ªã n·ªôi dung ƒëang stream
        response_placeholder = st.empty()
        full_response = ""
        
        with st.spinner("ƒêang t√¨m ki·∫øm t√†i li·ªáu..."):
            try:
                # B∆∞·ªõc A: Retrieval (gi·ªØ nguy√™n logic c·ªßa b·∫°n)
                vectorstore = get_vectorstore()
                retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
                docs = retriever.invoke(user_input)
                context_text = "\n\n".join(doc.page_content for doc in docs)

                # B∆∞·ªõc B: G·ªçi Chain v·ªõi ph∆∞∆°ng th·ª©c .stream()
                chain = get_rag_chain()
                history = st.session_state.messages[-6:] 
                
                # S·ª≠ d·ª•ng st.write_stream ƒë·ªÉ hi·ªÉn th·ªã hi·ªáu ·ª©ng g√µ ch·ªØ
                def generate_responses():
                    seen_content = set() # D√πng ƒë·ªÉ ki·ªÉm tra l·∫∑p t·ª´/c·ª•m t·ª´ c·ª±c ng·∫Øn n·∫øu c·∫ßn
                    full_text = ""
                    
                    for chunk in chain.stream({
                        "input": user_input,
                        "chat_history": history,
                        "context": context_text
                    }):
                        if chunk and hasattr(chunk, 'content'):
                            content = chunk.content
                            if content:
                                # Ki·ªÉm tra th·ªß c√¥ng: N·∫øu ƒëo·∫°n text m·ªõi ƒë√£ xu·∫•t hi·ªán qu√° nhi·ªÅu trong full_text
                                # ƒê√¢y l√† "ch·ªët ch·∫∑n" cu·ªëi c√πng n·∫øu Model v·∫´n c·ªë t√¨nh l·∫∑p
                                if full_text.count(content) > 3 and len(content) > 10:
                                    break
                                
                                full_text += content
                                yield content

                # Hi·ªÉn th·ªã stream tr·ª±c ti·∫øp l√™n giao di·ªán
                full_response = st.write_stream(generate_responses())
                
                # B∆∞·ªõc C: L∆∞u v√†o session v√† ghi log sau khi stream xong
                st.session_state.messages.append(AIMessage(content=full_response))
                save_log(user_input, context_text, full_response)
                
            except Exception as e:
                st.error(f"ƒê√£ x·∫£y ra l·ªói: {str(e)}")